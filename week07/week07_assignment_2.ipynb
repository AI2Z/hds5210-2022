{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 7 Assignment\n",
    "\n",
    "_MkKinney 6.1_\n",
    "\n",
    "This week has been all about getting information off the internet both in structured data formats (CSV, JSON, etc) as well as HTML.  For these exercises, we're going to use two practical examples of fetching data from web pages to show how to use Pandas and BeautifulSoup to extract structured information from the web.\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 33.1 Parsing a list in HTML\n",
    "\n",
    "Go to the Banner Health Price Transparency Page: https://www.bannerhealth.com/patients/billing/pricing-resources/hospital-price-transparency\n",
    "\n",
    "Notice that there is a list of hospitals and the city they are in.  We want to parse the underlying HTML to create a list of all the hospitals along with which city they're in.\n",
    "\n",
    "```json\n",
    "[\n",
    "    [\"Banner - University Medical Center Phoenix\", \"Arizona\"],\n",
    "    [\"Banner - University Medical Center South \", \"Arizona\"],\n",
    "    ...\n",
    "]\n",
    "```\n",
    "\n",
    "To examine the underlying HTML code, you can use Chrome, right-click, and choose **Inspect**.\n",
    "\n",
    "For reference, the documentation for BeautifulSoup is here: https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, create a function called **parse_banner(url)** that takes as it's one parameter the URL of the webpage to be parsed for links.  Make sure you include docstrings and a good test case using hte URL provided above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assignment 33.1 Parsing a list in HTML\n",
    "\n",
    "#Import Modules \n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "#run the header syntax \n",
    "headers = { \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 11_2_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36\" }\n",
    "#Note(per teacher): you'll need to fetch the data using the following syntax to include headers that make the web server think you're a real web browser.\n",
    "\n",
    "#assign url to object & check the site status(see footnotes below...)\n",
    "pageUrl = requests.get(\"https://www.bannerhealth.com/patients/billing/pricing-resources/hospital-price-transparency\", headers=headers)\n",
    "#print(page.status_code) #successful!\n",
    "\n",
    "#Preliminary Checks\n",
    "#check the text\n",
    "soup = BeautifulSoup(pageUrl.text, 'html.parser') #options: 'lxml', 'html.parser'\n",
    "# print(soup.prettify()) #too long...noprint\n",
    "\n",
    "#Letâ€™s see what the type of each element in the list is:\n",
    "# [type(item) for item in list(bannerSoup.children)]\n",
    "\n",
    "\n",
    "\n",
    "#footnotes (notes to self):\n",
    "#Note(page.status_code) a status code of 200 is good; 300 means the file may have moved... (see link... https://www.dataquest.io/blog/python-api-tutorial/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Modules \n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "#create function\n",
    "def parse_banner(url):\n",
    "    \"\"\"(url)->list\n",
    "    This function takes as it's one parameter the URL of the webpage to be parsed for links.\n",
    "    We want to parse the underlying HTML to create a list of all the hospitals along with which city they're in.\n",
    "    \n",
    "    >>> len(parse_banner('https://www.bannerhealth.com/patients/billing/pricing-resources/hospital-price-transparency'))\n",
    "    38\n",
    "    \"\"\"\n",
    " \n",
    "    #initialize the list\n",
    "    hospList = []\n",
    "    \n",
    "    #run the header syntax \n",
    "    headers = { \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 11_2_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36\" }\n",
    "    #Note(per teacher): you'll need to fetch the data using the following syntax to include headers that make the web server think you're a real web browser.\n",
    "    \n",
    "    #first, check the site status(see footnotes below)\n",
    "    page = requests.get(\"https://www.bannerhealth.com/patients/billing/pricing-resources/hospital-price-transparency\", headers=headers)\n",
    "    #print(page.status_code) #successful!\n",
    "\n",
    "    #next, check the text\n",
    "    bannerSoup = BeautifulSoup(page.text, 'html.parser') #options: 'lxml', 'html.parser'\n",
    "    # print(bannerSoup.prettify()) #too long...noprint\n",
    "\n",
    "    #assign tags to objects\n",
    "    div_class = bannerSoup.find_all(class_ = \"col-md-8\")[0] #col-md-8 => the class that contains the hospital pricing info\n",
    "    div_class_ul = div_class.find_all(\"ul\") #ul => the tag for the hospitals (ul=>unlabeled??)\n",
    "    div_class_ul_li = div_class.find_all(\"li\") #li => the tag that lists the specific hospitals within the ul hospital tag\n",
    "\n",
    "    #scrape the state info\n",
    "    #---get the list of states (#looking at the html, it seems the state names are listed under the \"strong\" tag)\n",
    "    #state_list = bannerSoup.find_all(\"strong\")[0:6]\n",
    "    state_list = div_class.find(\"strong\").get_text()\n",
    "   \n",
    "    #scrape the hospital info\n",
    "    #---get the list of hospitals (#looking at the html, it seems the hospital names are listed under the \"li\" tag)\n",
    "    hospital_list = div_class.find(\"li\").get_text()\n",
    "\n",
    "    #put everything together\n",
    "    for hosp_list in div_class_ul:\n",
    "        state = hosp_list.previous_sibling.previous_sibling.get_text() #used the \"previous_sibling\" syntax (see footnotes below...)\n",
    "        for hospital in hosp_list.find_all('li'):\n",
    "            hospList.append([hospital.text, state])\n",
    "            \n",
    "    return hospList\n",
    " \n",
    "#footnotes (notes to self):\n",
    "#Note(page.status_code) a status code of 200 is good; 300 means the file may have moved... (see link... https://www.dataquest.io/blog/python-api-tutorial/)\n",
    "#***loops \n",
    "#states = [st.get_text() for st in state_list] #loop through for all the states\n",
    "#hospitals = [hsp.get_text() for hsp in div_class_ul_li] #loop through for all the states\n",
    "#***Sibling info\n",
    "#used the \"previous_sibling\" syntax; state names are 2 tags away (<p>, <ul>, <li>) from the hospital list, based on tips from the instructor on slack... \n",
    "#...this (sibling syntax) was the only option that worked! (See link: https://www.crummy.com/software/BeautifulSoup/bs4/doc/#going-sideways)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding tests in NoName\n",
      "Trying:\n",
      "    len(parse_banner('https://www.bannerhealth.com/patients/billing/pricing-resources/hospital-price-transparency'))\n",
      "Expecting:\n",
      "    38\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "import doctest\n",
    "doctest.run_docstring_examples(parse_banner, globals(), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "banner = parse_banner('https://www.bannerhealth.com/patients/billing/pricing-resources/hospital-price-transparency')\n",
    "assert len(banner)==38, 'Length of result should have been 38, but {} returned.'.format(len(banner))\n",
    "assert banner[0][1]=='Arizona', 'Wrong data found in the first result item: {}'.format(banner[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 33.2 Using a REST API (from GitHub.com)\n",
    "\n",
    "Many websites provide something called a REST API to access information from their site programatically, rather than relying on HTML.  One example is GitHub.com, whose API allows you do to things like \"list all the public repositories for a user.\"\n",
    "\n",
    "The documentation for GitHub.com's REST API can be found here: https://docs.github.com/en/rest/guides/getting-started-with-the-rest-api\n",
    "\n",
    "Create a function called **repo_summary(user)** that takes a GitHub.com user name as it's parameter and retrieves a list of all the repositories you can see for that user.  The specific documentation for the this kind of request can be found here: https://docs.github.com/en/rest/reference/repos#list-repositories-for-a-user. Make sure your function is well documented with a docstring and includes a simple test to verify that you get back 12 repositories when querying for the repositories for user **paulboal**.\n",
    "\n",
    "I've provided a related example to help you out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This information is about paulboal. His website is www.amitechsolutions.com.\n",
      "{'login': 'paulboal', 'id': 1817916, 'node_id': 'MDQ6VXNlcjE4MTc5MTY=', 'avatar_url': 'https://avatars.githubusercontent.com/u/1817916?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/paulboal', 'html_url': 'https://github.com/paulboal', 'followers_url': 'https://api.github.com/users/paulboal/followers', 'following_url': 'https://api.github.com/users/paulboal/following{/other_user}', 'gists_url': 'https://api.github.com/users/paulboal/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/paulboal/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/paulboal/subscriptions', 'organizations_url': 'https://api.github.com/users/paulboal/orgs', 'repos_url': 'https://api.github.com/users/paulboal/repos', 'events_url': 'https://api.github.com/users/paulboal/events{/privacy}', 'received_events_url': 'https://api.github.com/users/paulboal/received_events', 'type': 'User', 'site_admin': False, 'name': 'Paul Boal', 'company': 'Amitech Solutions', 'blog': 'www.amitechsolutions.com', 'location': 'St. Louis, MO', 'email': None, 'hireable': None, 'bio': None, 'twitter_username': None, 'public_repos': 12, 'public_gists': 0, 'followers': 14, 'following': 9, 'created_at': '2012-06-05T04:36:06Z', 'updated_at': '2022-02-24T00:07:35Z'}\n"
     ]
    }
   ],
   "source": [
    "# Example -- this example of code shows how to get basic information on the user paulboal\n",
    "# For your solution, make sure you meet the requirements in the instructions above.\n",
    "\n",
    "import requests\n",
    "\n",
    "response = requests.get('https://api.github.com/users/paulboal')\n",
    "data = response.json()\n",
    "\n",
    "print('This information is about {}. His website is {}.'.format(data.get('login'), data.get('blog')))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code Here\n",
    "import requests\n",
    "import json\n",
    "\n",
    "def repo_summary(user):\n",
    "    \"\"\"(str)->list\n",
    "    This function takes a GitHub.com user name as it's parameter and \n",
    "    retrieves a list of all the repositories you can see for that user.\n",
    "    \n",
    "    >>> len(repo_summary('paulboal'))\n",
    "    12\n",
    "    \"\"\"\n",
    "    \n",
    "    #assign url to an object     \n",
    "    #link = \"https://api.github.com/users/{user}/repos\"\n",
    "    link = \"https://api.github.com/users/{}/repos\".format(user) #github API link \n",
    "\n",
    "    #request API link, convert to json etc.\n",
    "    api_link = requests.get(link)    \n",
    "    api_data = api_link.json()\n",
    "    repos_Data = (api_data)\n",
    "   \n",
    "    #initialize the final output list of repositories\n",
    "    repos = []    \n",
    "    \n",
    "    #append items to repos list\n",
    "    [repos.append(items['name']) for items in repos_Data]\n",
    "    \n",
    "    return repos\n",
    "    \n",
    "#footnotes (notes to self)\n",
    "#Note: need to include \".format(user)\" in the link for the tests below to work\n",
    "#(#options for repos...(users, org); e.g. https://api.github.com/repos/{owner}/{repo})\n",
    "#general format of the api link is 'https://api.github.com/users/{USERNAME}/repos'    \n",
    "#See link: https://www.w3schools.com/python/ref_string_format.asp (also see section on \"The Placeholders\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding tests in NoName\n",
      "Trying:\n",
      "    len(repo_summary('paulboal'))\n",
      "Expecting:\n",
      "    12\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "import doctest\n",
    "doctest.run_docstring_examples(repo_summary, globals(), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "repos = repo_summary('paulboal')\n",
    "assert len(repos)==12, 'Expecing 12, but {} were found'.format(len(repos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ajaxterm',\n",
       " 'cms_hospital_compare',\n",
       " 'collibra-scripts',\n",
       " 'coronadatascraper',\n",
       " 'hadoop-heuristicsminer',\n",
       " 'hds5210-2021',\n",
       " 'hds5210-2022',\n",
       " 'jupyterhub-nbgrader',\n",
       " 'nppes_demo',\n",
       " 'pexpect-curses',\n",
       " 'scm-products',\n",
       " 'tdwi-accelerate-2017-python']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test\n",
    "repo_summary('paulboal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 33.3 Find Something of Your Own\n",
    "\n",
    "Do some web searches and find an HTML page with some data that is interesting to something you're studying.  You can extract and parse that information using either BeautifulSoup or Pandas.  If you're using Pandas, then do something interesting to format and structure your data.  If you're using BeautifulSoup, you'll just need to do the work of parsing the data out of HTML -- that's hard enough!\n",
    "\n",
    "You don't need to build this as a function.  Just use notebook cells as I've done above.  You will be graded based on _style_.  Use variable names that make sense for your problem / solution. Cleanup anything you don't need before you submit your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Title: 10-day Weather Forecast for Des Moines, Iowa\n",
    "#Description: this code scrapes the 10-day weather forecast from weather.com for the city of Des Moines, Iowa.\n",
    "\n",
    "#*****************************************************************\n",
    "#Note: I did not find any information prohibiting the use of this site/data (see licensing info below)\n",
    "\n",
    "# 3.  Ownership; Limited License.\n",
    "# A. The Services are owned and operated by TWCPT, but the Services may include elements licensed from or provided by third parties. \n",
    "# TWCPT (along with its third party licensors) retains all right, title and interest in and to the Services, including all intellectual property rights in them. \n",
    "# The Services contain content (including, without limitation, data, text, software, images, video, graphics, music and sound) which is protected by United States \n",
    "# and worldwide copyright, trademark, trade secret, patent and other intellectual property laws, and with the exception of content in the public domain, \n",
    "# the rights to the content of the Services under such laws are owned or controlled by TWCPT or licensed from third parties.\n",
    "\n",
    "# B. Subject to all of the terms and conditions of these Terms of Use, TWCPT grants you a limited, personal, non-exclusive, non-sublicensable, non-transferable \n",
    "# license to access and use the Services for your personal, non-commercial use only.  \n",
    "# While you may access, view, use and display the Services for your personal, non-commercial use, you may not modify, reproduce, distribute,\n",
    "# publicly display, publicly perform, rent, lease, participate in the transfer or sale, create derivative works, or in any way exploit, any of the content, in whole or in part, except as expressly indicated by TWCPT in the Services, as expressly permitted under intellectual property laws, or with the express written permission of TWCPT and any relevant third party owners of intellectual property rights in the content. In the event of any permitted copying, redistribution or publication of protected material, you will not change or delete any author attribution, trademark legend or copyright notice, and no ownership rights will be transferred.  Some of the Services may include information sourced from the U.S. National Oceanic and Atmospheric Administration/National Weather Service, such as (without limitation) severe weather alerts, which information is in the public domain and is not subject to copyright protection.  T\n",
    "# WCPT does not claim to own or control such information.\n",
    "#*****************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Title: 10-day Weather Forecast for Des Moines, Iowa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "[<class 'bs4.element.Doctype'>, <class 'bs4.element.Tag'>]\n"
     ]
    }
   ],
   "source": [
    "# Your Code Here\n",
    "#Import Modules &Packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#assign url to object\n",
    "url = \"https://weather.com/weather/tenday/l/9f4008162d433e9dd2584077ace40c9fc72765c052152218f346dc729206e589\"\n",
    "\n",
    "#request page\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "print(page.status_code)\n",
    "#Notes on output: page status (200) is good!\n",
    "\n",
    "#quick checks\n",
    "#print(soup.prettify())\n",
    "#list(soup.children)\n",
    "\n",
    "#Letâ€™s see what the type for each element in the list is:\n",
    "print([type(item) for item in list(soup.children)])\n",
    "\n",
    "#Notes on output:\n",
    "#The first is a Doctype object, which contains information about the type of the document.\n",
    "#The second & final item is a Tag object, which contains other nested tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mon 07 | Night', 'Tue 08 | Day', 'Tue 08 | Night', 'Wed 09 | Day', 'Wed 09 | Night', 'Thu 10 | Day', 'Thu 10 | Night', 'Fri 11 | Day', 'Fri 11 | Night', 'Sat 12 | Day', 'Sat 12 | Night', 'Sun 13 | Day', 'Sun 13 | Night', 'Mon 14 | Day', 'Mon 14 | Night', 'Tue 15 | Day', 'Tue 15 | Night', 'Wed 16 | Day', 'Wed 16 | Night', 'Thu 17 | Day', 'Thu 17 | Night', 'Fri 18 | Day', 'Fri 18 | Night', 'Sat 19 | Day', 'Sat 19 | Night', 'Sun 20 | Day', 'Sun 20 | Night', 'Mon 21 | Day', 'Mon 21 | Night']\n",
      "-----------------------------\n",
      "['16Â°', '43Â°', '22Â°', '31Â°', '16Â°', '22Â°', '10Â°', '25Â°', '2Â°', '25Â°', '22Â°', '46Â°', '35Â°', '46Â°', '26Â°', '51Â°', '37Â°', '61Â°', '36Â°', '56Â°', '34Â°', '55Â°', '35Â°', '55Â°', '34Â°', '60Â°', '39Â°', '65Â°', '41Â°']\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "#10 Day Weather Forecast for Des Moines Iowa\n",
    "ten_day = soup.find(class_=\"DailyForecast--DisclosureList--msYIJ\") \n",
    "forecast_items = ten_day.find_all(class_=\"DaypartDetails--Content--hJ52O\")\n",
    "today = forecast_items[1]\n",
    "#today\n",
    "\n",
    "#use loops to iterate over the weekly forecasts...\n",
    "#first, get weekdays & time of the day(i.e. daytime vs. nightime)\n",
    "weekly_tags = ten_day.select(\".DailyForecast--DisclosureList--msYIJ .DailyContent--daypartName--1bzYn\")\n",
    "periods = [pt.get_text() for pt in weekly_tags]\n",
    "print(periods)\n",
    "print(\"-----------------------------\")\n",
    "\n",
    "#next, get the weekly temps\n",
    "weekly_temps = ten_day.select(\".DailyForecast--DisclosureList--msYIJ .DailyContent--temp--3d4dn\")\n",
    "temps = [tp.get_text() for tp in weekly_temps]\n",
    "print(temps)\n",
    "print(\"-----------------------------\")\n",
    "\n",
    "#next, get the weekly forecast descriptions\n",
    "weekly_descr = ten_day.select(\".DailyForecast--DisclosureList--msYIJ .DailyContent--narrative--hplRl\")\n",
    "descrs = [dscr.get_text() for dscr in weekly_descr]\n",
    "#print(descrs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day_period</th>\n",
       "      <th>temp</th>\n",
       "      <th>forecast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mon 07 | Night</td>\n",
       "      <td>16Â°</td>\n",
       "      <td>Clear skies. Low 16F. Winds light and variable.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tue 08 | Day</td>\n",
       "      <td>43Â°</td>\n",
       "      <td>Mostly sunny skies. High 43F. Winds SSW at 10 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tue 08 | Night</td>\n",
       "      <td>22Â°</td>\n",
       "      <td>Mostly cloudy skies early will become partly c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wed 09 | Day</td>\n",
       "      <td>31Â°</td>\n",
       "      <td>A mix of clouds and sun early, then becoming c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wed 09 | Night</td>\n",
       "      <td>16Â°</td>\n",
       "      <td>Cloudy with snow showers developing after midn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Thu 10 | Day</td>\n",
       "      <td>22Â°</td>\n",
       "      <td>Variably cloudy with snow showers. High 22F. W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Thu 10 | Night</td>\n",
       "      <td>10Â°</td>\n",
       "      <td>Mostly cloudy skies. Low near 10F. Winds NW at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Fri 11 | Day</td>\n",
       "      <td>25Â°</td>\n",
       "      <td>Partly to mostly cloudy. High around 25F. Wind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fri 11 | Night</td>\n",
       "      <td>2Â°</td>\n",
       "      <td>Clear skies. Low 2F. Winds NW at 10 to 15 mph.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sat 12 | Day</td>\n",
       "      <td>25Â°</td>\n",
       "      <td>Generally sunny despite a few afternoon clouds...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sat 12 | Night</td>\n",
       "      <td>22Â°</td>\n",
       "      <td>Partly cloudy skies. Low 22F. Winds SW at 10 t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Sun 13 | Day</td>\n",
       "      <td>46Â°</td>\n",
       "      <td>Sunny skies. High 46F. Winds WSW at 5 to 10 mph.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sun 13 | Night</td>\n",
       "      <td>35Â°</td>\n",
       "      <td>Partly cloudy. Low around 35F. Winds SSW at 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Mon 14 | Day</td>\n",
       "      <td>46Â°</td>\n",
       "      <td>Sunshine and clouds mixed. High 46F. Winds WNW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Mon 14 | Night</td>\n",
       "      <td>26Â°</td>\n",
       "      <td>A few clouds. Low 26F. Winds NNW at 10 to 15 mph.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Tue 15 | Day</td>\n",
       "      <td>51Â°</td>\n",
       "      <td>Partly cloudy skies. High 51F. WNW winds shift...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Tue 15 | Night</td>\n",
       "      <td>37Â°</td>\n",
       "      <td>Partly cloudy in the evening with more clouds ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Wed 16 | Day</td>\n",
       "      <td>61Â°</td>\n",
       "      <td>Considerable cloudiness. High 61F. Winds SW at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Wed 16 | Night</td>\n",
       "      <td>36Â°</td>\n",
       "      <td>Considerable cloudiness. Low 36F. Winds NNW at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Thu 17 | Day</td>\n",
       "      <td>56Â°</td>\n",
       "      <td>Showers in the morning with some clearing in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Thu 17 | Night</td>\n",
       "      <td>34Â°</td>\n",
       "      <td>Overcast with rain showers at times. Low 34F. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Fri 18 | Day</td>\n",
       "      <td>55Â°</td>\n",
       "      <td>Overcast with rain showers at times. High arou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Fri 18 | Night</td>\n",
       "      <td>35Â°</td>\n",
       "      <td>Showers in the evening, then partly cloudy ove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Sat 19 | Day</td>\n",
       "      <td>55Â°</td>\n",
       "      <td>Sunshine and clouds mixed. High near 55F. Wind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Sat 19 | Night</td>\n",
       "      <td>34Â°</td>\n",
       "      <td>Partly cloudy skies. Low 34F. Winds NW at 10 t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Sun 20 | Day</td>\n",
       "      <td>60Â°</td>\n",
       "      <td>Partly cloudy. High around 60F. Winds WSW at 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Sun 20 | Night</td>\n",
       "      <td>39Â°</td>\n",
       "      <td>A few clouds from time to time. Low 39F. Winds...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Mon 21 | Day</td>\n",
       "      <td>65Â°</td>\n",
       "      <td>Sunshine and clouds mixed. High around 65F. Wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Mon 21 | Night</td>\n",
       "      <td>41Â°</td>\n",
       "      <td>Partly cloudy. Low 41F. Winds SW at 10 to 15 mph.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        day_period temp                                           forecast\n",
       "0   Mon 07 | Night  16Â°    Clear skies. Low 16F. Winds light and variable.\n",
       "1     Tue 08 | Day  43Â°  Mostly sunny skies. High 43F. Winds SSW at 10 ...\n",
       "2   Tue 08 | Night  22Â°  Mostly cloudy skies early will become partly c...\n",
       "3     Wed 09 | Day  31Â°  A mix of clouds and sun early, then becoming c...\n",
       "4   Wed 09 | Night  16Â°  Cloudy with snow showers developing after midn...\n",
       "5     Thu 10 | Day  22Â°  Variably cloudy with snow showers. High 22F. W...\n",
       "6   Thu 10 | Night  10Â°  Mostly cloudy skies. Low near 10F. Winds NW at...\n",
       "7     Fri 11 | Day  25Â°  Partly to mostly cloudy. High around 25F. Wind...\n",
       "8   Fri 11 | Night   2Â°     Clear skies. Low 2F. Winds NW at 10 to 15 mph.\n",
       "9     Sat 12 | Day  25Â°  Generally sunny despite a few afternoon clouds...\n",
       "10  Sat 12 | Night  22Â°  Partly cloudy skies. Low 22F. Winds SW at 10 t...\n",
       "11    Sun 13 | Day  46Â°   Sunny skies. High 46F. Winds WSW at 5 to 10 mph.\n",
       "12  Sun 13 | Night  35Â°  Partly cloudy. Low around 35F. Winds SSW at 10...\n",
       "13    Mon 14 | Day  46Â°  Sunshine and clouds mixed. High 46F. Winds WNW...\n",
       "14  Mon 14 | Night  26Â°  A few clouds. Low 26F. Winds NNW at 10 to 15 mph.\n",
       "15    Tue 15 | Day  51Â°  Partly cloudy skies. High 51F. WNW winds shift...\n",
       "16  Tue 15 | Night  37Â°  Partly cloudy in the evening with more clouds ...\n",
       "17    Wed 16 | Day  61Â°  Considerable cloudiness. High 61F. Winds SW at...\n",
       "18  Wed 16 | Night  36Â°  Considerable cloudiness. Low 36F. Winds NNW at...\n",
       "19    Thu 17 | Day  56Â°  Showers in the morning with some clearing in t...\n",
       "20  Thu 17 | Night  34Â°  Overcast with rain showers at times. Low 34F. ...\n",
       "21    Fri 18 | Day  55Â°  Overcast with rain showers at times. High arou...\n",
       "22  Fri 18 | Night  35Â°  Showers in the evening, then partly cloudy ove...\n",
       "23    Sat 19 | Day  55Â°  Sunshine and clouds mixed. High near 55F. Wind...\n",
       "24  Sat 19 | Night  34Â°  Partly cloudy skies. Low 34F. Winds NW at 10 t...\n",
       "25    Sun 20 | Day  60Â°  Partly cloudy. High around 60F. Winds WSW at 1...\n",
       "26  Sun 20 | Night  39Â°  A few clouds from time to time. Low 39F. Winds...\n",
       "27    Mon 21 | Day  65Â°  Sunshine and clouds mixed. High around 65F. Wi...\n",
       "28  Mon 21 | Night  41Â°  Partly cloudy. Low 41F. Winds SW at 10 to 15 mph."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combine info in a dataframe\n",
    "import pandas as pd\n",
    "weather = pd.DataFrame({\n",
    "    \"day_period\": periods,\n",
    "    \"temp\": temps,\n",
    "    \"forecast\":descrs\n",
    "})\n",
    "weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Check your work above\n",
    "\n",
    "If you didn't get them all correct, take a few minutes to think through those that aren't correct.\n",
    "\n",
    "\n",
    "## Submitting Your Work\n",
    "\n",
    "In order to submit your work, you'll need to use the `git` command line program to **add** your homework file (this file) to your local repository, **commit** your changes to your local repository, and then **push** those changes up to github.com.  From there, I'll be able to **pull** the changes down and do my grading.  I'll provide some feedback, **commit** and **push** my comments back to you.  Next week, I'll show you how to **pull** down my comments.\n",
    "\n",
    "To run through everything one last time and submit your work:\n",
    "1. Use the `Kernel` -> `Restart Kernel and Run All Cells` menu option to run everything from top to bottom and stop here.\n",
    "2. Follow the instruction on the prompt below to either ssave and submit your work, or continue working.\n",
    "\n",
    "If anything fails along the way with this submission part of the process, let me know.  I'll help you troubleshoort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "a=input('''\n",
    "Are you ready to submit your work?\n",
    "1. Click the Save icon (or do Ctrl-S / Cmd-S)\n",
    "2. Type \"yes\" or \"no\" below\n",
    "3. Press Enter\n",
    "\n",
    "''')\n",
    "\n",
    "if a=='yes':\n",
    "    !git add week07_assignment_2.ipynb\n",
    "    !git commit -a -m \"Submitting the week 7 programming exercises\"\n",
    "    !git push\n",
    "else:\n",
    "    print('''\n",
    "    \n",
    "OK. We can wait.\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
